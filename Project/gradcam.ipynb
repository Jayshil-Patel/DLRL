{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Add a channel dimension to the images (required for the CNN)\n",
    "train_images = np.expand_dims(train_images, axis=-1)\n",
    "test_images = np.expand_dims(test_images, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 24s 12ms/step - loss: 0.1428 - accuracy: 0.9554\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0464 - accuracy: 0.9854\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0329 - accuracy: 0.9896\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0243 - accuracy: 0.9922\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0178 - accuracy: 0.9941\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1d7e6034d10>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_grad_cam(model, img, layer_name):\n",
    "    # Get the model's output tensor\n",
    "    output = model.output\n",
    "\n",
    "    # Get the convolutional layer you want to visualize\n",
    "    layer = model.get_layer(layer_name)\n",
    "\n",
    "    # Calculate the gradient of the target class with regard to the output feature map of the selected layer\n",
    "    grads = tf.gradients(output, layer.output)[0]\n",
    "\n",
    "    # Average the gradients spatially\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # Create a function to access the values of the intermediate layer and gradients\n",
    "    iterate = keras.backend.function([model.input], [pooled_grads, layer.output[0]])\n",
    "\n",
    "    # Get the pooled gradients and the output feature map of the selected layer\n",
    "    pooled_grads_value, layer_output_value = iterate([img])\n",
    "\n",
    "    # Multiply each channel in the feature map by \"how important this channel is\" with regard to the target class\n",
    "    for i in range(layer_output_value.shape[-1]):\n",
    "        layer_output_value[:, :, i] *= pooled_grads_value[i]\n",
    "\n",
    "    # Average the weighted feature map\n",
    "    heatmap = np.mean(layer_output_value, axis=-1)\n",
    "\n",
    "    return heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "tf.gradients is not supported when eager execution is enabled. Use tf.GradientTape instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\jaysh\\FALL2023\\DLRL\\Project\\gradcam.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/Project/gradcam.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m predicted_class \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(class_probabilities)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/Project/gradcam.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Generate Grad-CAM heatmap for the predicted class\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/Project/gradcam.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m heatmap \u001b[39m=\u001b[39m generate_grad_cam(model, np\u001b[39m.\u001b[39;49mexpand_dims(test_image, axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m), \u001b[39m'\u001b[39;49m\u001b[39mconv2d\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;32md:\\jaysh\\FALL2023\\DLRL\\Project\\gradcam.ipynb Cell 5\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/Project/gradcam.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m layer \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mget_layer(layer_name)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/Project/gradcam.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Calculate the gradient of the target class with regard to the output feature map of the selected layer\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/Project/gradcam.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m grads \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mgradients(output, layer\u001b[39m.\u001b[39;49moutput)[\u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/Project/gradcam.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Average the gradients spatially\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/Project/gradcam.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m pooled_grads \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mreduce_mean(grads, axis\u001b[39m=\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:318\u001b[0m, in \u001b[0;36mgradients_v2\u001b[1;34m(ys, xs, grad_ys, name, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[39m# Creating the gradient graph for control flow mutates Operations.\u001b[39;00m\n\u001b[0;32m    314\u001b[0m \u001b[39m# _mutation_lock ensures a Session.run call cannot occur between creating and\u001b[39;00m\n\u001b[0;32m    315\u001b[0m \u001b[39m# mutating new ops.\u001b[39;00m\n\u001b[0;32m    316\u001b[0m \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mget_default_graph()\u001b[39m.\u001b[39m_mutation_lock():\n\u001b[1;32m--> 318\u001b[0m   \u001b[39mreturn\u001b[39;00m gradients_util\u001b[39m.\u001b[39;49m_GradientsHelper(\n\u001b[0;32m    319\u001b[0m       ys, xs, grad_ys, name, \u001b[39mTrue\u001b[39;49;00m, gate_gradients,\n\u001b[0;32m    320\u001b[0m       aggregation_method, stop_gradients,\n\u001b[0;32m    321\u001b[0m       unconnected_gradients)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:498\u001b[0m, in \u001b[0;36m_GradientsHelper\u001b[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Implementation of gradients().\"\"\"\u001b[39;00m\n\u001b[0;32m    497\u001b[0m \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 498\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mtf.gradients is not supported when eager execution \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    499\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mis enabled. Use tf.GradientTape instead.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    500\u001b[0m ys \u001b[39m=\u001b[39m variable_utils\u001b[39m.\u001b[39mconvert_variables_to_tensors(_AsList(ys))\n\u001b[0;32m    501\u001b[0m xs \u001b[39m=\u001b[39m [\n\u001b[0;32m    502\u001b[0m     x\u001b[39m.\u001b[39mhandle \u001b[39mif\u001b[39;00m resource_variable_ops\u001b[39m.\u001b[39mis_resource_variable(x) \u001b[39melse\u001b[39;00m x\n\u001b[0;32m    503\u001b[0m     \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m _AsList(xs)\n\u001b[0;32m    504\u001b[0m ]\n",
      "\u001b[1;31mRuntimeError\u001b[0m: tf.gradients is not supported when eager execution is enabled. Use tf.GradientTape instead."
     ]
    }
   ],
   "source": [
    "# Select an image from the test set\n",
    "image_index = 0\n",
    "test_image = test_images[image_index]\n",
    "\n",
    "# Predict the class probabilities for the image\n",
    "class_probabilities = model.predict(np.expand_dims(test_image, axis=0))\n",
    "\n",
    "# Get the class with the highest probability\n",
    "predicted_class = np.argmax(class_probabilities)\n",
    "\n",
    "# Generate Grad-CAM heatmap for the predicted class\n",
    "heatmap = generate_grad_cam(model, np.expand_dims(test_image, axis=0), 'conv2d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'(' was never closed (399497210.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[14], line 6\u001b[1;36m\u001b[0m\n\u001b[1;33m    class_probabilities = model.predict(np.expand_dims(test_image, axis=0)\u001b[0m\n\u001b[1;37m                                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m '(' was never closed\n"
     ]
    }
   ],
   "source": [
    "# Select an image from the test set\n",
    "image_index = 0\n",
    "test_image = test_images[image_index]\n",
    "\n",
    "# Predict the class probabilities for the image\n",
    "class_probabilities = model.predict(np.expand_dims(test_image, axis=0)\n",
    "\n",
    "# Get the class with the highest probability\n",
    "predicted_class = np.argmax(class_probabilities)\n",
    "\n",
    "# Generate Grad-CAM heatmap for the predicted class\n",
    "heatmap = generate_grad_cam(model, np.expand_dims(test_image, axis=0), 'conv2d_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale the heatmap to be between 0 and 1\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "heatmap /= np.max(heatmap)\n",
    "\n",
    "# Resize the heatmap to match the original image size\n",
    "heatmap = cv2.resize(heatmap, (test_image.shape[1], test_image.shape[0]))\n",
    "heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "# Apply a heatmap color map\n",
    "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "\n",
    "# Overlay the heatmap on the original image\n",
    "superimposed_img = cv2.addWeighted(test_image.squeeze(), 0.6, heatmap, 0.4, 0)\n",
    "\n",
    "# Display the original image, Grad-CAM heatmap, and the superimposed image\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(test_image.squeeze(), cmap='gray')\n",
    "plt.title('Original Image')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(heatmap)\n",
    "plt.title('Grad-CAM Heatmap')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(superimposed_img, cmap='jet')\n",
    "plt.title('Superimposed Image')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.1424 - accuracy: 0.9561\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0466 - accuracy: 0.9855\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0320 - accuracy: 0.9902\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0243 - accuracy: 0.9926\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0182 - accuracy: 0.9942\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No such layer: conv2d_2. Existing layers are: ['conv2d_4', 'max_pooling2d_4', 'conv2d_5', 'max_pooling2d_5', 'flatten_2', 'dense_4', 'dense_5'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\jaysh\\FALL2023\\DLRL\\Project\\gradcam.ipynb Cell 8\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/Project/gradcam.ipynb#X11sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m test_image \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexpand_dims(test_image, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/Project/gradcam.ipynb#X11sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m \u001b[39m# Generate Grad-CAM heatmap for the predicted class\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/Project/gradcam.ipynb#X11sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m heatmap \u001b[39m=\u001b[39m generate_grad_cam(model, test_image, \u001b[39m'\u001b[39;49m\u001b[39mconv2d_2\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/Project/gradcam.ipynb#X11sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39m# Rescale the heatmap to be between 0 and 1\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/Project/gradcam.ipynb#X11sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m heatmap \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmaximum(heatmap, \u001b[39m0\u001b[39m)\n",
      "\u001b[1;32md:\\jaysh\\FALL2023\\DLRL\\Project\\gradcam.ipynb Cell 8\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/Project/gradcam.ipynb#X11sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m class_idx \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39margmax(output[\u001b[39m0\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/Project/gradcam.ipynb#X11sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m# Get the convolutional layer you want to visualize\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/Project/gradcam.ipynb#X11sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m layer \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mget_layer(layer_name)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/Project/gradcam.ipynb#X11sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m# Calculate the feature map\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/Project/gradcam.ipynb#X11sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m target_layer_output \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39moutput\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:3543\u001b[0m, in \u001b[0;36mModel.get_layer\u001b[1;34m(self, name, index)\u001b[0m\n\u001b[0;32m   3541\u001b[0m         \u001b[39mif\u001b[39;00m layer\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m name:\n\u001b[0;32m   3542\u001b[0m             \u001b[39mreturn\u001b[39;00m layer\n\u001b[1;32m-> 3543\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   3544\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo such layer: \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m. Existing layers are: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3545\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(layer\u001b[39m.\u001b[39mname\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mlayer\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3546\u001b[0m     )\n\u001b[0;32m   3547\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   3548\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mProvide either a layer name or layer index at `get_layer`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3549\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: No such layer: conv2d_2. Existing layers are: ['conv2d_4', 'max_pooling2d_4', 'conv2d_5', 'max_pooling2d_5', 'flatten_2', 'dense_4', 'dense_5']."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load MNIST dataset\n",
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Add a channel dimension to the images (required for the CNN)\n",
    "train_images = np.expand_dims(train_images, axis=-1)\n",
    "test_images = np.expand_dims(test_images, axis=-1)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "\n",
    "def generate_grad_cam(model, img, layer_name):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Get the model's output tensor\n",
    "        output = model(img)\n",
    "        class_idx = tf.argmax(output[0])\n",
    "        # Get the convolutional layer you want to visualize\n",
    "        layer = model.get_layer(layer_name)\n",
    "        # Calculate the feature map\n",
    "        target_layer_output = layer.output\n",
    "    grads = tape.gradient(output, target_layer_output)[0]\n",
    "\n",
    "    # Calculate the weights\n",
    "    weights = tf.reduce_mean(grads, axis=(0, 1))\n",
    "\n",
    "    # Get the feature map from the selected layer\n",
    "    feature_map = model.get_layer(layer_name).output[0]\n",
    "\n",
    "    # Generate the heatmap\n",
    "    heatmap = tf.reduce_sum(tf.multiply(weights, feature_map), axis=-1)\n",
    "\n",
    "    return heatmap\n",
    "\n",
    "# Select an image from the test set\n",
    "image_index = 0\n",
    "test_image = test_images[image_index]\n",
    "\n",
    "# Expand dimensions for batch size\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "\n",
    "# Generate Grad-CAM heatmap for the predicted class\n",
    "heatmap = generate_grad_cam(model, test_image, 'conv2d_4')\n",
    "\n",
    "# Rescale the heatmap to be between 0 and 1\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "heatmap /= tf.reduce_max(heatmap)\n",
    "\n",
    "# Resize the heatmap to match the original image size\n",
    "heatmap = tf.image.resize(heatmap, (28, 28))\n",
    "\n",
    "# Convert to numpy array\n",
    "heatmap = heatmap.numpy()\n",
    "\n",
    "# Apply a heatmap color map\n",
    "heatmap = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n",
    "\n",
    "# Overlay the heatmap on the original image\n",
    "superimposed_img = cv2.addWeighted(test_image[0], 0.6, heatmap, 0.4, 0)\n",
    "\n",
    "# Display the original image, Grad-CAM heatmap, and the superimposed image\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(test_image[0].squeeze(), cmap='gray')\n",
    "plt.title('Original Image')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(heatmap.squeeze(), cmap='jet')\n",
    "plt.title('Grad-CAM Heatmap')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(superimposed_img)\n",
    "plt.title('Superimposed Image')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KerasTensor' object has no attribute '_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\jaysh\\FALL2023\\DLRL\\Project\\gradcam.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/Project/gradcam.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Generate Grad-CAM heatmap for the predicted class\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/Project/gradcam.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m heatmap \u001b[39m=\u001b[39m generate_grad_cam(model, test_image, \u001b[39m'\u001b[39;49m\u001b[39mconv2d_4\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/Project/gradcam.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Rescale the heatmap to be between 0 and 1\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/Project/gradcam.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m heatmap \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmaximum(heatmap, \u001b[39m0\u001b[39m)\n",
      "\u001b[1;32md:\\jaysh\\FALL2023\\DLRL\\Project\\gradcam.ipynb Cell 9\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/Project/gradcam.ipynb#X12sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     \u001b[39m# Calculate the feature map\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/Project/gradcam.ipynb#X12sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     target_layer_output \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39moutput\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/Project/gradcam.ipynb#X12sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m grads \u001b[39m=\u001b[39m tape\u001b[39m.\u001b[39;49mgradient(output, target_layer_output)[\u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/Project/gradcam.ipynb#X12sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39m# Calculate the weights\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/Project/gradcam.ipynb#X12sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m weights \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mreduce_mean(grads, axis\u001b[39m=\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\backprop.py:1065\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1059\u001b[0m   output_gradients \u001b[39m=\u001b[39m (\n\u001b[0;32m   1060\u001b[0m       composite_tensor_gradient\u001b[39m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[0;32m   1061\u001b[0m           output_gradients))\n\u001b[0;32m   1062\u001b[0m   output_gradients \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m ops\u001b[39m.\u001b[39mconvert_to_tensor(x)\n\u001b[0;32m   1063\u001b[0m                       \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m output_gradients]\n\u001b[1;32m-> 1065\u001b[0m flat_grad \u001b[39m=\u001b[39m imperative_grad\u001b[39m.\u001b[39;49mimperative_grad(\n\u001b[0;32m   1066\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tape,\n\u001b[0;32m   1067\u001b[0m     flat_targets,\n\u001b[0;32m   1068\u001b[0m     flat_sources,\n\u001b[0;32m   1069\u001b[0m     output_gradients\u001b[39m=\u001b[39;49moutput_gradients,\n\u001b[0;32m   1070\u001b[0m     sources_raw\u001b[39m=\u001b[39;49mflat_sources_raw,\n\u001b[0;32m   1071\u001b[0m     unconnected_gradients\u001b[39m=\u001b[39;49munconnected_gradients)\n\u001b[0;32m   1073\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_persistent:\n\u001b[0;32m   1074\u001b[0m   \u001b[39m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[0;32m   1075\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_watched_variables \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tape\u001b[39m.\u001b[39mwatched_variables()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     65\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mUnknown value for unconnected_gradients: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m unconnected_gradients)\n\u001b[1;32m---> 67\u001b[0m \u001b[39mreturn\u001b[39;00m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_TapeGradient(\n\u001b[0;32m     68\u001b[0m     tape\u001b[39m.\u001b[39;49m_tape,  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m     69\u001b[0m     target,\n\u001b[0;32m     70\u001b[0m     sources,\n\u001b[0;32m     71\u001b[0m     output_gradients,\n\u001b[0;32m     72\u001b[0m     sources_raw,\n\u001b[0;32m     73\u001b[0m     compat\u001b[39m.\u001b[39;49mas_str(unconnected_gradients\u001b[39m.\u001b[39;49mvalue))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KerasTensor' object has no attribute '_id'"
     ]
    }
   ],
   "source": [
    "# Generate Grad-CAM heatmap for the predicted class\n",
    "heatmap = generate_grad_cam(model, test_image, 'conv2d_4')\n",
    "\n",
    "# Rescale the heatmap to be between 0 and 1\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "heatmap /= tf.reduce_max(heatmap)\n",
    "\n",
    "# Resize the heatmap to match the original image size\n",
    "heatmap = tf.image.resize(heatmap, (28, 28))\n",
    "\n",
    "# Convert to numpy array\n",
    "heatmap = heatmap.numpy()\n",
    "\n",
    "# Apply a heatmap color map\n",
    "heatmap = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n",
    "\n",
    "# Overlay the heatmap on the original image\n",
    "superimposed_img = cv2.addWeighted(test_image[0], 0.6, heatmap, 0.4, 0)\n",
    "\n",
    "# Display the original image, Grad-CAM heatmap, and the superimposed image\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(test_image[0].squeeze(), cmap='gray')\n",
    "plt.title('Original Image')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(heatmap.squeeze(), cmap='jet')\n",
    "plt.title('Grad-CAM Heatmap')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(superimposed_img)\n",
    "plt.title('Superimposed Image')\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
