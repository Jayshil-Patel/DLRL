{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\softwares\\Python\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "d:\\softwares\\Python\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "d:\\softwares\\Python\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "d:\\softwares\\Python\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "d:\\softwares\\Python\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 3s 841us/step - loss: 0.4709 - accuracy: 0.8775 - val_loss: 0.3082 - val_accuracy: 0.9160\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 1s 705us/step - loss: 0.3039 - accuracy: 0.9148 - val_loss: 0.2813 - val_accuracy: 0.9238\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 1s 713us/step - loss: 0.2834 - accuracy: 0.9209 - val_loss: 0.2729 - val_accuracy: 0.9241\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 1s 676us/step - loss: 0.2733 - accuracy: 0.9234 - val_loss: 0.2692 - val_accuracy: 0.9263\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 1s 702us/step - loss: 0.2665 - accuracy: 0.9254 - val_loss: 0.2666 - val_accuracy: 0.9265\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 1s 700us/step - loss: 0.2618 - accuracy: 0.9276 - val_loss: 0.2635 - val_accuracy: 0.9278\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 1s 700us/step - loss: 0.2580 - accuracy: 0.9283 - val_loss: 0.2656 - val_accuracy: 0.9270\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 1s 710us/step - loss: 0.2551 - accuracy: 0.9291 - val_loss: 0.2657 - val_accuracy: 0.9256\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 1s 703us/step - loss: 0.2524 - accuracy: 0.9301 - val_loss: 0.2631 - val_accuracy: 0.9271\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 1s 707us/step - loss: 0.2507 - accuracy: 0.9307 - val_loss: 0.2638 - val_accuracy: 0.9275\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 10)                7850      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 2s 812us/step - loss: 3.5714 - accuracy: 0.7090 - val_loss: 0.3184 - val_accuracy: 0.9121\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 1s 740us/step - loss: 3.4309 - accuracy: 0.7404 - val_loss: 0.2939 - val_accuracy: 0.9187\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 1s 744us/step - loss: 3.4322 - accuracy: 0.7420 - val_loss: 0.2817 - val_accuracy: 0.9223\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 1s 732us/step - loss: 3.3973 - accuracy: 0.7460 - val_loss: 0.2701 - val_accuracy: 0.9240\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 1s 741us/step - loss: 3.4191 - accuracy: 0.7466 - val_loss: 0.2721 - val_accuracy: 0.9239\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 1s 731us/step - loss: 3.4101 - accuracy: 0.7479 - val_loss: 0.2731 - val_accuracy: 0.9238\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 1s 788us/step - loss: 3.3970 - accuracy: 0.7494 - val_loss: 0.2700 - val_accuracy: 0.9258\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 1s 791us/step - loss: 3.4027 - accuracy: 0.7492 - val_loss: 0.2708 - val_accuracy: 0.9233\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 1s 765us/step - loss: 3.4113 - accuracy: 0.7488 - val_loss: 0.2698 - val_accuracy: 0.9244\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 1s 785us/step - loss: 3.3777 - accuracy: 0.7519 - val_loss: 0.2667 - val_accuracy: 0.9255\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 10)                7850      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 10)                40        \n",
      "=================================================================\n",
      "Total params: 7,890\n",
      "Trainable params: 7,870\n",
      "Non-trainable params: 20\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 2s 957us/step - loss: 6.6578 - accuracy: 0.2148 - val_loss: 7.6071 - val_accuracy: 0.1615\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 2s 874us/step - loss: 7.5240 - accuracy: 0.2802 - val_loss: 6.9128 - val_accuracy: 0.4032\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 2s 856us/step - loss: 6.6018 - accuracy: 0.2950 - val_loss: 7.5555 - val_accuracy: 0.2422\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 2s 865us/step - loss: 7.4710 - accuracy: 0.3011 - val_loss: 6.1399 - val_accuracy: 0.2749\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 2s 866us/step - loss: 7.2264 - accuracy: 0.1906 - val_loss: 7.6058 - val_accuracy: 0.1611\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 2s 906us/step - loss: 8.3269 - accuracy: 0.1319 - val_loss: 9.2301 - val_accuracy: 0.1061\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 2s 860us/step - loss: 8.2166 - accuracy: 0.1098 - val_loss: 8.1839 - val_accuracy: 0.1014\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 2s 869us/step - loss: 8.3582 - accuracy: 0.1020 - val_loss: 8.1642 - val_accuracy: 0.1002\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 2s 840us/step - loss: 8.2356 - accuracy: 0.0992 - val_loss: 8.6285 - val_accuracy: 0.0992\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 2s 846us/step - loss: 8.5168 - accuracy: 0.0983 - val_loss: 8.1836 - val_accuracy: 0.0982\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "x_train = x_train.reshape((-1, 28 * 28))\n",
    "x_test = x_test.reshape((-1, 28 * 28))\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Define the softmax regression model\n",
    "def softmax_regression_model(input_shape=(784, )):\n",
    "    model = models.Sequential([\n",
    "        layers.Dense(10, activation='softmax', input_shape=input_shape)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Define the model with dropout\n",
    "def softmax_regression_model_with_dropout(input_shape=(784, ), dropout_rate=0.2):\n",
    "    model = models.Sequential([\n",
    "        layers.Dense(10, activation='softmax', input_shape=input_shape),\n",
    "        layers.Dropout(dropout_rate)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Define the model with batch normalization\n",
    "def softmax_regression_model_with_batch_norm(input_shape=(784, )):\n",
    "    model = models.Sequential([\n",
    "        layers.Dense(10, activation='softmax', input_shape=input_shape),\n",
    "        layers.BatchNormalization()\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Train and evaluate the models\n",
    "def train_and_evaluate(model, x_train, y_train, x_test, y_test):\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))\n",
    "\n",
    "# Train and evaluate the softmax regression model\n",
    "softmax_reg_model = softmax_regression_model()\n",
    "train_and_evaluate(softmax_reg_model, x_train, y_train, x_test, y_test)\n",
    "\n",
    "# Train and evaluate the softmax regression model with dropout\n",
    "softmax_reg_model_with_dropout = softmax_regression_model_with_dropout(dropout_rate=0.2)\n",
    "train_and_evaluate(softmax_reg_model_with_dropout, x_train, y_train, x_test, y_test)\n",
    "\n",
    "# Train and evaluate the softmax regression model with batch normalization\n",
    "softmax_reg_model_with_batch_norm = softmax_regression_model_with_batch_norm()\n",
    "train_and_evaluate(softmax_reg_model_with_batch_norm, x_train, y_train, x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 109,386\n",
      "Trainable params: 109,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2338 - accuracy: 0.9321 - val_loss: 0.1290 - val_accuracy: 0.9594\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0990 - accuracy: 0.9694 - val_loss: 0.1107 - val_accuracy: 0.9674\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0722 - accuracy: 0.9775 - val_loss: 0.0795 - val_accuracy: 0.9753\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0536 - accuracy: 0.9832 - val_loss: 0.0827 - val_accuracy: 0.9750\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0439 - accuracy: 0.9860 - val_loss: 0.0878 - val_accuracy: 0.9740\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0345 - accuracy: 0.9889 - val_loss: 0.0855 - val_accuracy: 0.9762\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 2s 993us/step - loss: 0.0290 - accuracy: 0.9903 - val_loss: 0.0792 - val_accuracy: 0.9778\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0233 - accuracy: 0.9926 - val_loss: 0.0844 - val_accuracy: 0.9770\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0206 - accuracy: 0.9932 - val_loss: 0.0925 - val_accuracy: 0.9789\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0191 - accuracy: 0.9936 - val_loss: 0.0818 - val_accuracy: 0.9811\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 109,386\n",
      "Trainable params: 109,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3289 - accuracy: 0.9022 - val_loss: 0.1343 - val_accuracy: 0.9589\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 2s 998us/step - loss: 0.1558 - accuracy: 0.9528 - val_loss: 0.1085 - val_accuracy: 0.9658\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1222 - accuracy: 0.9631 - val_loss: 0.0928 - val_accuracy: 0.9732\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1044 - accuracy: 0.9682 - val_loss: 0.0819 - val_accuracy: 0.9749\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0915 - accuracy: 0.9720 - val_loss: 0.0777 - val_accuracy: 0.9775\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0816 - accuracy: 0.9744 - val_loss: 0.0765 - val_accuracy: 0.9777\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0742 - accuracy: 0.9769 - val_loss: 0.0757 - val_accuracy: 0.9786\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0704 - accuracy: 0.9776 - val_loss: 0.0676 - val_accuracy: 0.9795\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0645 - accuracy: 0.9798 - val_loss: 0.0740 - val_accuracy: 0.9788\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0622 - accuracy: 0.9807 - val_loss: 0.0728 - val_accuracy: 0.9793\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 110,154\n",
      "Trainable params: 109,770\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2504 - accuracy: 0.9268 - val_loss: 0.1201 - val_accuracy: 0.9608\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1242 - accuracy: 0.9622 - val_loss: 0.0981 - val_accuracy: 0.9696\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0953 - accuracy: 0.9703 - val_loss: 0.0802 - val_accuracy: 0.9755\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0796 - accuracy: 0.9747 - val_loss: 0.0883 - val_accuracy: 0.9725\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0653 - accuracy: 0.9799 - val_loss: 0.0787 - val_accuracy: 0.9755\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0585 - accuracy: 0.9814 - val_loss: 0.0766 - val_accuracy: 0.9751\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0513 - accuracy: 0.9837 - val_loss: 0.0698 - val_accuracy: 0.9780\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0451 - accuracy: 0.9853 - val_loss: 0.0768 - val_accuracy: 0.9773\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0401 - accuracy: 0.9866 - val_loss: 0.0707 - val_accuracy: 0.9786\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0361 - accuracy: 0.9881 - val_loss: 0.0684 - val_accuracy: 0.9795\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "x_train = x_train.reshape((-1, 28 * 28))\n",
    "x_test = x_test.reshape((-1, 28 * 28))\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Define the MLP model\n",
    "def mlp_model(input_shape=(784, )):\n",
    "    model = models.Sequential([\n",
    "        layers.Dense(128, activation='relu', input_shape=input_shape),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Define the MLP model with dropout\n",
    "def mlp_model_with_dropout(input_shape=(784, ), dropout_rate=0.2):\n",
    "    model = models.Sequential([\n",
    "        layers.Dense(128, activation='relu', input_shape=input_shape),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Define the MLP model with batch normalization\n",
    "def mlp_model_with_batch_norm(input_shape=(784, )):\n",
    "    model = models.Sequential([\n",
    "        layers.Dense(128, activation='relu', input_shape=input_shape),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Train and evaluate the models\n",
    "def train_and_evaluate(model, x_train, y_train, x_test, y_test):\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))\n",
    "\n",
    "# Train and evaluate the MLP model\n",
    "mlp_model = mlp_model()\n",
    "train_and_evaluate(mlp_model, x_train, y_train, x_test, y_test)\n",
    "\n",
    "# Train and evaluate the MLP model with dropout\n",
    "mlp_model_with_dropout = mlp_model_with_dropout(dropout_rate=0.2)\n",
    "train_and_evaluate(mlp_model_with_dropout, x_train, y_train, x_test, y_test)\n",
    "\n",
    "# Train and evaluate the MLP model with batch normalization\n",
    "mlp_model_with_batch_norm = mlp_model_with_batch_norm()\n",
    "train_and_evaluate(mlp_model_with_batch_norm, x_train, y_train, x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               692352    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 693,962\n",
      "Trainable params: 693,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 15s 7ms/step - loss: 0.1446 - accuracy: 0.9574 - val_loss: 0.0642 - val_accuracy: 0.9799\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0500 - accuracy: 0.9850 - val_loss: 0.0496 - val_accuracy: 0.9838\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0313 - accuracy: 0.9905 - val_loss: 0.0437 - val_accuracy: 0.9849\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0206 - accuracy: 0.9939 - val_loss: 0.0419 - val_accuracy: 0.9864\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0141 - accuracy: 0.9958 - val_loss: 0.0499 - val_accuracy: 0.9851\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0102 - accuracy: 0.9967 - val_loss: 0.0467 - val_accuracy: 0.9860\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0073 - accuracy: 0.9975 - val_loss: 0.0529 - val_accuracy: 0.9858\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0073 - accuracy: 0.9972 - val_loss: 0.0621 - val_accuracy: 0.9847\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.0523 - val_accuracy: 0.9877\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.0669 - val_accuracy: 0.9859\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 128)               692352    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 693,962\n",
      "Trainable params: 693,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.1734 - accuracy: 0.9484 - val_loss: 0.0586 - val_accuracy: 0.9806\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0624 - accuracy: 0.9813 - val_loss: 0.0430 - val_accuracy: 0.9853\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0439 - accuracy: 0.9866 - val_loss: 0.0384 - val_accuracy: 0.9872\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0343 - accuracy: 0.9891 - val_loss: 0.0419 - val_accuracy: 0.9862\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0254 - accuracy: 0.9915 - val_loss: 0.0414 - val_accuracy: 0.9865\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0206 - accuracy: 0.9934 - val_loss: 0.0462 - val_accuracy: 0.9860\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0169 - accuracy: 0.9944 - val_loss: 0.0414 - val_accuracy: 0.9882\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0140 - accuracy: 0.9952 - val_loss: 0.0476 - val_accuracy: 0.9863\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0123 - accuracy: 0.9956 - val_loss: 0.0510 - val_accuracy: 0.9871\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0102 - accuracy: 0.9962 - val_loss: 0.0488 - val_accuracy: 0.9879\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               692352    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 694,602\n",
      "Trainable params: 694,282\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 22s 11ms/step - loss: 0.1142 - accuracy: 0.9655 - val_loss: 0.0541 - val_accuracy: 0.9832\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0471 - accuracy: 0.9852 - val_loss: 0.0500 - val_accuracy: 0.9834\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0306 - accuracy: 0.9903 - val_loss: 0.0506 - val_accuracy: 0.9838\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 23s 13ms/step - loss: 0.0216 - accuracy: 0.9929 - val_loss: 0.0539 - val_accuracy: 0.9845\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.0159 - accuracy: 0.9945 - val_loss: 0.0457 - val_accuracy: 0.9853\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 25s 13ms/step - loss: 0.0118 - accuracy: 0.9960 - val_loss: 0.0729 - val_accuracy: 0.9811\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 25s 13ms/step - loss: 0.0115 - accuracy: 0.9961 - val_loss: 0.0460 - val_accuracy: 0.9881\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 25s 13ms/step - loss: 0.0076 - accuracy: 0.9978 - val_loss: 0.0473 - val_accuracy: 0.9881\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 25s 13ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.0581 - val_accuracy: 0.9871\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 25s 14ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.0652 - val_accuracy: 0.9856\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "x_train = x_train.reshape((-1, 28, 28, 1))\n",
    "x_test = x_test.reshape((-1, 28, 28, 1))\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Define the CNN model\n",
    "def cnn_model(input_shape=(28, 28, 1)):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Define the CNN model with dropout\n",
    "def cnn_model_with_dropout(input_shape=(28, 28, 1), dropout_rate=0.2):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Define the CNN model with batch normalization\n",
    "def cnn_model_with_batch_norm(input_shape=(28, 28, 1)):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Train and evaluate the models\n",
    "def train_and_evaluate(model, x_train, y_train, x_test, y_test):\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))\n",
    "\n",
    "# Train and evaluate the CNN model\n",
    "cnn_model = cnn_model()\n",
    "train_and_evaluate(cnn_model, x_train, y_train, x_test, y_test)\n",
    "\n",
    "# Train and evaluate the CNN model with dropout\n",
    "cnn_model_with_dropout = cnn_model_with_dropout(dropout_rate=0.2)\n",
    "train_and_evaluate(cnn_model_with_dropout, x_train, y_train, x_test, y_test)\n",
    "\n",
    "# Train and evaluate the CNN model with batch normalization\n",
    "cnn_model_with_batch_norm = cnn_model_with_batch_norm()\n",
    "train_and_evaluate(cnn_model_with_batch_norm, x_train, y_train, x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
