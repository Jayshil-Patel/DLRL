{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, SimpleRNN\n",
    "import matplotlib.pyplot as plt\n",
    "import keras_tuner as kt\n",
    "from keras_tuner import RandomSearch\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def load_data(data_folder):\n",
    "    reviews = []\n",
    "    labels = []\n",
    "    \n",
    "    for label in ['pos', 'neg']:\n",
    "        folder_path = os.path.join(data_folder, label)\n",
    "        for filename in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                review = file.read()\n",
    "                reviews.append(review)\n",
    "                labels.append(1 if label == 'pos' else 0)\n",
    "    \n",
    "    return reviews, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "data_folder_train = 'D:\\\\jaysh\\\\FALL2023\\\\DLRL\\\\HW3\\\\dataset\\\\train'  # Replace with the actual path to your dataset\n",
    "data_folder_test = 'D:\\\\jaysh\\\\FALL2023\\\\DLRL\\\\HW3\\\\dataset\\\\test'  # Replace with the actual path to your dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\jaysh\\FALL2023\\DLRL\\HW3\\try.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/HW3/try.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m X_train, y_train \u001b[39m=\u001b[39m load_data(data_folder_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/HW3/try.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m X_test, y_test \u001b[39m=\u001b[39m load_data(data_folder_test)\n",
      "\u001b[1;32md:\\jaysh\\FALL2023\\DLRL\\HW3\\try.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/HW3/try.ipynb#W3sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(folder_path):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/HW3/try.ipynb#W3sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     file_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(folder_path, filename)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/HW3/try.ipynb#W3sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(file_path, \u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m, encoding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m file:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/HW3/try.ipynb#W3sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m         review \u001b[39m=\u001b[39m file\u001b[39m.\u001b[39mread()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/HW3/try.ipynb#W3sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         reviews\u001b[39m.\u001b[39mappend(review)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    280\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    281\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    283\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    284\u001b[0m     )\n\u001b[1;32m--> 286\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m<frozen codecs>:309\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, errors)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train, y_train = load_data(data_folder_train)\n",
    "X_test, y_test = load_data(data_folder_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Initialize the TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "# Fit and transform the training data\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = np.array(y_train), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = X_train_tfidf.toarray()\n",
    "X_test = X_test_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\jaysh\\FALL2023\\DLRL\\HW3\\try.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/HW3/try.ipynb#X15sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Tokenize the text\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/HW3/try.ipynb#X15sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m Tokenizer()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/HW3/try.ipynb#X15sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m tokenizer\u001b[39m.\u001b[39;49mfit_on_texts(X_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/HW3/try.ipynb#X15sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m X_train_seq \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mtexts_to_sequences(X_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/HW3/try.ipynb#X15sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m X_test_seq \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mtexts_to_sequences(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\preprocessing\\text.py:293\u001b[0m, in \u001b[0;36mTokenizer.fit_on_texts\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    292\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39manalyzer \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 293\u001b[0m         seq \u001b[39m=\u001b[39m text_to_word_sequence(\n\u001b[0;32m    294\u001b[0m             text,\n\u001b[0;32m    295\u001b[0m             filters\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilters,\n\u001b[0;32m    296\u001b[0m             lower\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlower,\n\u001b[0;32m    297\u001b[0m             split\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msplit,\n\u001b[0;32m    298\u001b[0m         )\n\u001b[0;32m    299\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    300\u001b[0m         seq \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39manalyzer(text)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\preprocessing\\text.py:74\u001b[0m, in \u001b[0;36mtext_to_word_sequence\u001b[1;34m(input_text, filters, lower, split)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Converts a text to a sequence of words (or tokens).\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \n\u001b[0;32m     48\u001b[0m \u001b[39mDeprecated: `tf.keras.preprocessing.text.text_to_word_sequence` does not\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[39m    A list of words (or tokens).\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[39mif\u001b[39;00m lower:\n\u001b[1;32m---> 74\u001b[0m     input_text \u001b[39m=\u001b[39m input_text\u001b[39m.\u001b[39;49mlower()\n\u001b[0;32m     76\u001b[0m translate_dict \u001b[39m=\u001b[39m {c: split \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m filters}\n\u001b[0;32m     77\u001b[0m translate_map \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m\u001b[39m.\u001b[39mmaketrans(translate_dict)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Assuming you have X_train, X_test, y_train, y_test\n",
    "\n",
    "# Set hyperparameters\n",
    "state_dimensions = [20, 50, 100, 200, 500]\n",
    "embedding_dim = 100\n",
    "max_len = 5000\n",
    "\n",
    "# Tokenize the text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Pad sequences to a fixed length\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)\n",
    "\n",
    "# Model building function\n",
    "def build_rnn_model(state_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len, trainable=True))\n",
    "    model.add(SimpleRNN(units=state_dim))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_lstm_model(state_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len, trainable=True))\n",
    "    model.add(LSTM(units=state_dim))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Train and evaluate models\n",
    "results_rnn = []\n",
    "results_lstm = []\n",
    "\n",
    "for state_dim in state_dimensions:\n",
    "    # RNN\n",
    "    rnn_model = build_rnn_model(state_dim)\n",
    "    rnn_model.fit(X_train_pad, y_train, epochs=5, batch_size=64, validation_split=0.2, verbose=0)\n",
    "    rnn_result = rnn_model.evaluate(X_test_pad, y_test, verbose=0)\n",
    "    results_rnn.append((state_dim, rnn_result[1]))  # Accuracy is at index 1\n",
    "    \n",
    "    # LSTM\n",
    "    lstm_model = build_lstm_model(state_dim)\n",
    "    lstm_model.fit(X_train_pad, y_train, epochs=5, batch_size=64, validation_split=0.2, verbose=0)\n",
    "    lstm_result = lstm_model.evaluate(X_test_pad, y_test, verbose=0)\n",
    "    results_lstm.append((state_dim, lstm_result[1]))\n",
    "\n",
    "# Display results\n",
    "print(\"RNN Results:\")\n",
    "print(\"State Dimension\\tAccuracy\")\n",
    "for result in results_rnn:\n",
    "    print(f\"{result[0]}\\t\\t\\t{result[1]}\")\n",
    "\n",
    "print(\"\\nLSTM Results:\")\n",
    "print(\"State Dimension\\tAccuracy\")\n",
    "for result in results_lstm:\n",
    "    print(f\"{result[0]}\\t\\t\\t{result[1]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
