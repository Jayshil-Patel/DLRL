{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02f1feff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50406546",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, SimpleRNN\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e24fa616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "from keras_tuner import RandomSearch\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e2ae3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def load_data(data_folder):\n",
    "    reviews = []\n",
    "    labels = []\n",
    "    \n",
    "    for label in ['pos', 'neg']:\n",
    "        folder_path = os.path.join(data_folder, label)\n",
    "        for filename in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                review = file.read()\n",
    "                reviews.append(review)\n",
    "                labels.append(1 if label == 'pos' else 0)\n",
    "    \n",
    "    return reviews, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "data_folder_train = 'D:\\\\jaysh\\\\FALL2023\\\\DLRL\\\\HW3\\\\dataset\\\\train'  # Replace with the actual path to your dataset\n",
    "data_folder_test = 'D:\\\\jaysh\\\\FALL2023\\\\DLRL\\\\HW3\\\\dataset\\\\test'  # Replace with the actual path to your dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_data(data_folder_train)\n",
    "X_test, y_test = load_data(data_folder_test)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Initialize the TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "# Fit and transform the training data\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "y_train, y_test = np.array(y_train), np.array(y_test)\n",
    "\n",
    "X_train = X_train_tfidf.toarray()\n",
    "X_test = X_test_tfidf.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3018687",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model20(hp):\n",
    "    vocab_size = 5000\n",
    "    embedding_size = 128\n",
    "    model=Sequential()\n",
    "    model.add(Embedding(vocab_size, embedding_size, input_length=20))\n",
    "    model.add(SimpleRNN(units=128, input_shape=(None, 1), dropout = hp.Choice(\"dropout\", values=[0.0, 0.4, 0.5, 0.6])))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    #print(model.summary())\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                 optimizer=keras.optimizers.Adam(hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4])), \n",
    "                 metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_model50(hp):\n",
    "    vocab_size = 5000\n",
    "    embedding_size = 128\n",
    "    model=Sequential()\n",
    "    model.add(Embedding(vocab_size, embedding_size, input_length=50))\n",
    "    model.add(SimpleRNN(units=128, input_shape=(None, 1), dropout = hp.Choice(\"dropout\", values=[0.0, 0.4, 0.5, 0.6])))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    #print(model.summary())\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                 optimizer=keras.optimizers.Adam(hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4])), \n",
    "                 metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_model100(hp):\n",
    "    vocab_size = 5000\n",
    "    embedding_size = 128\n",
    "    model=Sequential()\n",
    "    model.add(Embedding(vocab_size, embedding_size, input_length=100))\n",
    "    model.add(SimpleRNN(units=128, input_shape=(None, 1), dropout = hp.Choice(\"dropout\", values=[0.0, 0.4, 0.5, 0.6])))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    #print(model.summary())\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                 optimizer=keras.optimizers.Adam(hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4])), \n",
    "                 metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_model200(hp):\n",
    "    vocab_size = 5000\n",
    "    embedding_size = 128\n",
    "    model=Sequential()\n",
    "    model.add(Embedding(vocab_size, embedding_size, input_length=200))\n",
    "    model.add(SimpleRNN(units=128, input_shape=(None, 1), dropout = hp.Choice(\"dropout\", values=[0.0, 0.4, 0.5, 0.6])))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    #print(model.summary())\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                 optimizer=keras.optimizers.Adam(hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4])), \n",
    "                 metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_model500(hp):\n",
    "    vocab_size = 5000\n",
    "    embedding_size = 128\n",
    "    model=Sequential()\n",
    "    model.add(Embedding(vocab_size, embedding_size, input_length=500))\n",
    "    model.add(SimpleRNN(units=128, input_shape=(None, 1), dropout = hp.Choice(\"dropout\", values=[0.0, 0.4, 0.5, 0.6])))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    #print(model.summary())\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                 optimizer=keras.optimizers.Adam(hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4])), \n",
    "                 metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acca10f4",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning for state dimensions = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3edb91",
   "metadata": {},
   "source": [
    "## batchsize 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e14bf308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 01m 11s]\n",
      "accuracy: 0.5044657289981842\n",
      "\n",
      "Best accuracy So Far: 0.5044657289981842\n",
      "Total elapsed time: 00h 03m 37s\n",
      "Results summary\n",
      "Results in my_dir\\helloworld\n",
      "Showing 10 best trials\n",
      "Objective(name=\"accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 2 summary\n",
      "Hyperparameters:\n",
      "dropout: 0.4\n",
      "learning_rate: 0.0001\n",
      "Score: 0.5044657289981842\n",
      "\n",
      "Trial 0 summary\n",
      "Hyperparameters:\n",
      "dropout: 0.6\n",
      "learning_rate: 0.01\n",
      "Score: 0.5025832951068878\n",
      "\n",
      "Trial 1 summary\n",
      "Hyperparameters:\n",
      "dropout: 0.0\n",
      "learning_rate: 0.0001\n",
      "Score: 0.49951939284801483\n",
      "\n",
      "********************************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#20 state dimensions batch_size 32\n",
    "X20_train = sequence.pad_sequences(X_train, maxlen=20)\n",
    "X20_test = sequence.pad_sequences(X_test, maxlen=20)\n",
    "bsize = 32\n",
    "X_valid, y_valid = X20_train[:bsize], y_train[:bsize]\n",
    "X_train2, y_train2 = X20_train[bsize:], y_train[bsize:]\n",
    "tuner = RandomSearch(\n",
    "    build_model20,\n",
    "    objective=\"accuracy\",\n",
    "    max_trials=3,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"helloworld\",\n",
    ")\n",
    "tuner.search(X_train2, y_train2, epochs=3, validation_data=(X_valid, y_valid), batch_size = bsize)\n",
    "tuner.results_summary()\n",
    "print(\"\\n********************************************************************************\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a129df",
   "metadata": {},
   "source": [
    "## batchsize 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c21e69ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 00m 52s]\n",
      "accuracy: 0.5017244219779968\n",
      "\n",
      "Best accuracy So Far: 0.5029275119304657\n",
      "Total elapsed time: 00h 02m 37s\n",
      "Results summary\n",
      "Results in my_dir\\helloworld\n",
      "Showing 10 best trials\n",
      "Objective(name=\"accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 0 summary\n",
      "Hyperparameters:\n",
      "dropout: 0.5\n",
      "learning_rate: 0.01\n",
      "Score: 0.5029275119304657\n",
      "\n",
      "Trial 2 summary\n",
      "Hyperparameters:\n",
      "dropout: 0.6\n",
      "learning_rate: 0.001\n",
      "Score: 0.5017244219779968\n",
      "\n",
      "Trial 1 summary\n",
      "Hyperparameters:\n",
      "dropout: 0.6\n",
      "learning_rate: 0.01\n",
      "Score: 0.5\n",
      "\n",
      "********************************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#20 state dimensions batch_size 64\n",
    "X20_train = sequence.pad_sequences(X_train, maxlen=20)\n",
    "X20_test = sequence.pad_sequences(X_test, maxlen=20)\n",
    "bsize = 64\n",
    "X_valid, y_valid = X20_train[:bsize], y_train[:bsize]\n",
    "X_train2, y_train2 = X20_train[bsize:], y_train[bsize:]\n",
    "tuner = RandomSearch(\n",
    "    build_model20,\n",
    "    objective=\"accuracy\",\n",
    "    max_trials=3,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"helloworld\",\n",
    ")\n",
    "tuner.search(X_train2, y_train2, epochs=3, validation_data=(X_valid, y_valid), batch_size = bsize)\n",
    "tuner.results_summary()\n",
    "print(\"\\n********************************************************************************\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17f7390",
   "metadata": {},
   "source": [
    "## batch size 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cb688fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 01m 01s]\n",
      "accuracy: 0.5003613829612732\n",
      "\n",
      "Best accuracy So Far: 0.5016864538192749\n",
      "Total elapsed time: 00h 02m 36s\n",
      "Results summary\n",
      "Results in my_dir\\helloworld\n",
      "Showing 10 best trials\n",
      "Objective(name=\"accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 0 summary\n",
      "Hyperparameters:\n",
      "dropout: 0.4\n",
      "learning_rate: 0.001\n",
      "Score: 0.5016864538192749\n",
      "\n",
      "Trial 1 summary\n",
      "Hyperparameters:\n",
      "dropout: 0.6\n",
      "learning_rate: 0.01\n",
      "Score: 0.5015860795974731\n",
      "\n",
      "Trial 2 summary\n",
      "Hyperparameters:\n",
      "dropout: 0.5\n",
      "learning_rate: 0.01\n",
      "Score: 0.5003613829612732\n",
      "\n",
      "********************************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#20 state dimensions batch_size 96\n",
    "X20_train = sequence.pad_sequences(X_train, maxlen=20)\n",
    "X20_test = sequence.pad_sequences(X_test, maxlen=20)\n",
    "bsize = 96\n",
    "X_valid, y_valid = X20_train[:bsize], y_train[:bsize]\n",
    "X_train2, y_train2 = X20_train[bsize:], y_train[bsize:]\n",
    "tuner = RandomSearch(\n",
    "    build_model20,\n",
    "    objective=\"accuracy\",\n",
    "    max_trials=3,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"helloworld\",\n",
    ")\n",
    "tuner.search(X_train2, y_train2, epochs=3, validation_data=(X_valid, y_valid), batch_size = bsize)\n",
    "tuner.results_summary()\n",
    "print(\"\\n********************************************************************************\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae0c966",
   "metadata": {},
   "source": [
    "# State dimensions 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471c7b7b",
   "metadata": {},
   "source": [
    "## batch size 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7b8ebaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 01m 51s]\n",
      "accuracy: 0.5015419721603394\n",
      "\n",
      "Best accuracy So Far: 0.5054669976234436\n",
      "Total elapsed time: 00h 05m 59s\n",
      "Results summary\n",
      "Results in my_dir\\helloworld\n",
      "Showing 10 best trials\n",
      "Objective(name=\"accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 0 summary\n",
      "Hyperparameters:\n",
      "dropout: 0.5\n",
      "learning_rate: 0.0001\n",
      "Score: 0.5054669976234436\n",
      "\n",
      "Trial 2 summary\n",
      "Hyperparameters:\n",
      "dropout: 0.4\n",
      "learning_rate: 0.0001\n",
      "Score: 0.5015419721603394\n",
      "\n",
      "Trial 1 summary\n",
      "Hyperparameters:\n",
      "dropout: 0.6\n",
      "learning_rate: 0.01\n",
      "Score: 0.500660851597786\n",
      "\n",
      "********************************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#50 state dimensions batch_size 32\n",
    "X50_train = sequence.pad_sequences(X_train, maxlen=50)\n",
    "X50_test = sequence.pad_sequences(X_test, maxlen=50)\n",
    "bsize = 32\n",
    "X_valid, y_valid = X50_train[:bsize], y_train[:bsize]\n",
    "X_train2, y_train2 = X50_train[bsize:], y_train[bsize:]\n",
    "tuner = RandomSearch(\n",
    "    build_model50,\n",
    "    objective=\"accuracy\",\n",
    "    max_trials=3,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"helloworld\",\n",
    ")\n",
    "tuner.search(X_train2, y_train2, epochs=3, validation_data=(X_valid, y_valid), batch_size = bsize)\n",
    "tuner.results_summary()\n",
    "print(\"\\n********************************************************************************\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dfe61e",
   "metadata": {},
   "source": [
    "## batch size 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b44e710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 01m 31s]\n",
      "accuracy: 0.5019048750400543\n",
      "\n",
      "Best accuracy So Far: 0.5041306018829346\n",
      "Total elapsed time: 00h 04m 28s\n",
      "Results summary\n",
      "Results in my_dir\\helloworld\n",
      "Showing 10 best trials\n",
      "Objective(name=\"accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 0 summary\n",
      "Hyperparameters:\n",
      "dropout: 0.0\n",
      "learning_rate: 0.01\n",
      "Score: 0.5041306018829346\n",
      "\n",
      "Trial 1 summary\n",
      "Hyperparameters:\n",
      "dropout: 0.0\n",
      "learning_rate: 0.0001\n",
      "Score: 0.5026868581771851\n",
      "\n",
      "Trial 2 summary\n",
      "Hyperparameters:\n",
      "dropout: 0.4\n",
      "learning_rate: 0.0001\n",
      "Score: 0.5019048750400543\n",
      "\n",
      "********************************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#50 state dimensions batch_size 64\n",
    "X50_train = sequence.pad_sequences(X_train, maxlen=50)\n",
    "X50_test = sequence.pad_sequences(X_test, maxlen=50)\n",
    "bsize = 64\n",
    "X_valid, y_valid = X50_train[:bsize], y_train[:bsize]\n",
    "X_train2, y_train2 = X50_train[bsize:], y_train[bsize:]\n",
    "tuner = RandomSearch(\n",
    "    build_model50,\n",
    "    objective=\"accuracy\",\n",
    "    max_trials=3,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"helloworld\",\n",
    ")\n",
    "tuner.search(X_train2, y_train2, epochs=3, validation_data=(X_valid, y_valid), batch_size = bsize)\n",
    "tuner.results_summary()\n",
    "print(\"\\n********************************************************************************\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed6c47e",
   "metadata": {},
   "source": [
    "## batch size 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b58d431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 01m 15s]\n",
      "accuracy: 0.503453254699707\n",
      "\n",
      "Best accuracy So Far: 0.5064447522163391\n",
      "Total elapsed time: 00h 03m 41s\n",
      "Results summary\n",
      "Results in my_dir\\helloworld\n",
      "Showing 10 best trials\n",
      "Objective(name=\"accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 1 summary\n",
      "Hyperparameters:\n",
      "dropout: 0.5\n",
      "learning_rate: 0.01\n",
      "Score: 0.5064447522163391\n",
      "\n",
      "Trial 2 summary\n",
      "Hyperparameters:\n",
      "dropout: 0.6\n",
      "learning_rate: 0.001\n",
      "Score: 0.503453254699707\n",
      "\n",
      "Trial 0 summary\n",
      "Hyperparameters:\n",
      "dropout: 0.4\n",
      "learning_rate: 0.01\n",
      "Score: 0.5016463398933411\n",
      "\n",
      "********************************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#50 state dimensions batch_size 96\n",
    "X50_train = sequence.pad_sequences(X_train, maxlen=50)\n",
    "X50_test = sequence.pad_sequences(X_test, maxlen=50)\n",
    "bsize = 96\n",
    "X_valid, y_valid = X50_train[:bsize], y_train[:bsize]\n",
    "X_train2, y_train2 = X50_train[bsize:], y_train[bsize:]\n",
    "tuner = RandomSearch(\n",
    "    build_model50,\n",
    "    objective=\"accuracy\",\n",
    "    max_trials=3,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"helloworld\",\n",
    ")\n",
    "tuner.search(X_train2, y_train2, epochs=3, validation_data=(X_valid, y_valid), batch_size = bsize)\n",
    "tuner.results_summary()\n",
    "print(\"\\n********************************************************************************\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9d9878",
   "metadata": {},
   "source": [
    "# State dimensions 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabbbebb",
   "metadata": {},
   "source": [
    "## batch size 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44926c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 03m 24s]\n",
      "accuracy: 0.49983978271484375\n",
      "\n",
      "Best accuracy So Far: 0.5028436481952667\n",
      "Total elapsed time: 00h 06m 05s\n",
      "\n",
      "Search: Running Trial #3\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "0.6               |0                 |dropout\n",
      "0.01              |0.001             |learning_rate\n",
      "\n",
      "Epoch 1/3\n",
      "781/781 [==============================] - 37s 42ms/step - loss: 0.7110 - accuracy: 0.5003 - val_loss: 0.9739 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/3\n",
      "781/781 [==============================] - 32s 41ms/step - loss: 0.7107 - accuracy: 0.5002 - val_loss: 0.6876 - val_accuracy: 1.0000\n",
      "Epoch 3/3\n",
      "781/781 [==============================] - 32s 40ms/step - loss: 0.7130 - accuracy: 0.5011 - val_loss: 0.7631 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/3\n",
      "781/781 [==============================] - 34s 39ms/step - loss: 0.7120 - accuracy: 0.4938 - val_loss: 0.5735 - val_accuracy: 1.0000\n",
      "Epoch 2/3\n",
      " 55/781 [=>............................] - ETA: 27s - loss: 0.7150 - accuracy: 0.4949"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\jaysh\\FALL2023\\DLRL\\HW3\\diff\\Exercise 3.ipynb Cell 24\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/HW3/diff/Exercise%203.ipynb#X32sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m X_train2, y_train2 \u001b[39m=\u001b[39m X100_train[bsize:], y_train[bsize:]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/HW3/diff/Exercise%203.ipynb#X32sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m tuner \u001b[39m=\u001b[39m RandomSearch(\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/HW3/diff/Exercise%203.ipynb#X32sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     build_model100,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/HW3/diff/Exercise%203.ipynb#X32sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     objective\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/HW3/diff/Exercise%203.ipynb#X32sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     project_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhelloworld\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/HW3/diff/Exercise%203.ipynb#X32sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/HW3/diff/Exercise%203.ipynb#X32sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m tuner\u001b[39m.\u001b[39;49msearch(X_train2, y_train2, epochs\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(X_valid, y_valid), batch_size \u001b[39m=\u001b[39;49m bsize)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/HW3/diff/Exercise%203.ipynb#X32sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m tuner\u001b[39m.\u001b[39mresults_summary()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/jaysh/FALL2023/DLRL/HW3/diff/Exercise%203.ipynb#X32sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m********************************************************************************\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:233\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    230\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m    232\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_begin(trial)\n\u001b[1;32m--> 233\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_run_and_update_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[0;32m    234\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_end(trial)\n\u001b[0;32m    235\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_search_end()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:273\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_run_and_update_trial\u001b[39m(\u001b[39mself\u001b[39m, trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs):\n\u001b[0;32m    272\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 273\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_and_update_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[0;32m    274\u001b[0m         trial\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m trial_module\u001b[39m.\u001b[39mTrialStatus\u001b[39m.\u001b[39mCOMPLETED\n\u001b[0;32m    275\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:238\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_and_update_trial\u001b[39m(\u001b[39mself\u001b[39m, trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs):\n\u001b[1;32m--> 238\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[0;32m    239\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mget_trial(trial\u001b[39m.\u001b[39mtrial_id)\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mexists(\n\u001b[0;32m    240\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mobjective\u001b[39m.\u001b[39mname\n\u001b[0;32m    241\u001b[0m     ):\n\u001b[0;32m    242\u001b[0m         \u001b[39m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[0;32m    243\u001b[0m         \u001b[39m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[0;32m    244\u001b[0m         \u001b[39m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[0;32m    245\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    246\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe use case of calling \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    247\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    253\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m    254\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras_tuner\\src\\engine\\tuner.py:314\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    312\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(model_checkpoint)\n\u001b[0;32m    313\u001b[0m     copied_kwargs[\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m callbacks\n\u001b[1;32m--> 314\u001b[0m     obj_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_and_fit_model(trial, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcopied_kwargs)\n\u001b[0;32m    316\u001b[0m     histories\u001b[39m.\u001b[39mappend(obj_value)\n\u001b[0;32m    317\u001b[0m \u001b[39mreturn\u001b[39;00m histories\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras_tuner\\src\\engine\\tuner.py:233\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    231\u001b[0m hp \u001b[39m=\u001b[39m trial\u001b[39m.\u001b[39mhyperparameters\n\u001b[0;32m    232\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_build(hp)\n\u001b[1;32m--> 233\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhypermodel\u001b[39m.\u001b[39;49mfit(hp, model, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    235\u001b[0m \u001b[39m# Save the build config for model loading later.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[39mif\u001b[39;00m backend\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mmulti_backend():\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py:149\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[1;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, hp, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    126\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Train the model.\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \n\u001b[0;32m    128\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[39m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 149\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39;49mfit(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1776\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1777\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1780\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1781\u001b[0m ):\n\u001b[0;32m   1782\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1783\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1784\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1785\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    828\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 831\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    833\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    834\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    864\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    865\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    866\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m   \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    868\u001b[0m       args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_config\n\u001b[0;32m    869\u001b[0m   )\n\u001b[0;32m    870\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    872\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1260\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1261\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1262\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1263\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1264\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mflat_call(args)\n\u001b[0;32m   1265\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1266\u001b[0m     args,\n\u001b[0;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1268\u001b[0m     executing_eagerly)\n\u001b[0;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflat_call\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    216\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    218\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[0;32m    251\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 252\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    253\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    254\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[0;32m    255\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[0;32m    256\u001b[0m     )\n\u001b[0;32m    257\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    259\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m    260\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[0;32m    261\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[0;32m    262\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1477\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[0;32m   1478\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1479\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m   1480\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1481\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[0;32m   1482\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[0;32m   1483\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1484\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1485\u001b[0m   )\n\u001b[0;32m   1486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1487\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1488\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1489\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1493\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[0;32m   1494\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#100 state dimensions batch_size 32\n",
    "X100_train = sequence.pad_sequences(X_train, maxlen=100)\n",
    "X100_test = sequence.pad_sequences(X_test, maxlen=100)\n",
    "bsize = 32\n",
    "X_valid, y_valid = X100_train[:bsize], y_train[:bsize]\n",
    "X_train2, y_train2 = X100_train[bsize:], y_train[bsize:]\n",
    "tuner = RandomSearch(\n",
    "    build_model100,\n",
    "    objective=\"accuracy\",\n",
    "    max_trials=3,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"helloworld\",\n",
    ")\n",
    "tuner.search(X_train2, y_train2, epochs=3, validation_data=(X_valid, y_valid), batch_size = bsize)\n",
    "tuner.results_summary()\n",
    "print(\"\\n********************************************************************************\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0d3041",
   "metadata": {},
   "source": [
    "## batch size 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1933641b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 01m 38s]\n",
      "val_accuracy: 1.0\n",
      "\n",
      "Best val_accuracy So Far: 1.0\n",
      "Total elapsed time: 00h 04m 52s\n",
      "Results summary\n",
      "Results in my_dir\\helloworld\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 0 summary\n",
      "Hyperparameters:\n",
      "dropout: 0.0\n",
      "learning_rate: 0.001\n",
      "Score: 1.0\n",
      "\n",
      "Trial 1 summary\n",
      "Hyperparameters:\n",
      "dropout: 0.5\n",
      "learning_rate: 0.0001\n",
      "Score: 1.0\n",
      "\n",
      "Trial 2 summary\n",
      "Hyperparameters:\n",
      "dropout: 0.6\n",
      "learning_rate: 0.001\n",
      "Score: 1.0\n",
      "\n",
      "********************************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#100 state dimensions batch_size 64\n",
    "X100_train = sequence.pad_sequences(X_train, maxlen=100)\n",
    "X100_test = sequence.pad_sequences(X_test, maxlen=100)\n",
    "bsize = 64\n",
    "X_valid, y_valid = X100_train[:bsize], y_train[:bsize]\n",
    "X_train2, y_train2 = X100_train[bsize:], y_train[bsize:]\n",
    "tuner = RandomSearch(\n",
    "    build_model100,\n",
    "    objective=\"accuracy\",\n",
    "    max_trials=3,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"helloworld\",\n",
    ")\n",
    "tuner.search(X_train2, y_train2, epochs=3, validation_data=(X_valid, y_valid), batch_size = bsize)\n",
    "tuner.results_summary()\n",
    "print(\"\\n********************************************************************************\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7c39f8",
   "metadata": {},
   "source": [
    "## batch size 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0467e805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 01m 31s]\n",
      "val_accuracy: 1.0\n",
      "\n",
      "Best val_accuracy So Far: 1.0\n",
      "Total elapsed time: 00h 05m 00s\n",
      "Results summary\n",
      "Results in my_dir\\helloworld\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 2 summary\n",
      "Hyperparameters:\n",
      "dropout: 0.0\n",
      "learning_rate: 0.0001\n",
      "Score: 1.0\n",
      "\n",
      "Trial 0 summary\n",
      "Hyperparameters:\n",
      "dropout: 0.5\n",
      "learning_rate: 0.01\n",
      "Score: 0.5\n",
      "\n",
      "Trial 1 summary\n",
      "Hyperparameters:\n",
      "dropout: 0.6\n",
      "learning_rate: 0.01\n",
      "Score: 0.5\n",
      "\n",
      "********************************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#100 state dimensions batch_size 96\n",
    "X100_train = sequence.pad_sequences(X_train, maxlen=100)\n",
    "X100_test = sequence.pad_sequences(X_test, maxlen=100)\n",
    "bsize = 96\n",
    "X_valid, y_valid = X100_train[:bsize], y_train[:bsize]\n",
    "X_train2, y_train2 = X100_train[bsize:], y_train[bsize:]\n",
    "tuner = RandomSearch(\n",
    "    build_model100,\n",
    "    objective=\"accuracy\",\n",
    "    max_trials=3,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"helloworld\",\n",
    ")\n",
    "tuner.search(X_train2, y_train2, epochs=3, validation_data=(X_valid, y_valid), batch_size = bsize)\n",
    "tuner.results_summary()\n",
    "print(\"\\n********************************************************************************\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a0418e",
   "metadata": {},
   "source": [
    "# State dimensions 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8804ff3d",
   "metadata": {},
   "source": [
    "## batch size 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4866238b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 04m 19s]\n",
      "val_accuracy: 1.0\n",
      "\n",
      "Best val_accuracy So Far: 1.0\n",
      "Total elapsed time: 00h 11m 02s\n",
      "Results summary\n",
      "Results in my_dir\\helloworld\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 0 summary\n",
      "Hyperparameters:\n",
      "dropout: 0.6\n",
      "learning_rate: 0.0001\n",
      "Score: 1.0\n",
      "\n",
      "Trial 2 summary\n",
      "Hyperparameters:\n",
      "dropout: 0.4\n",
      "learning_rate: 0.0001\n",
      "Score: 1.0\n",
      "\n",
      "Trial 1 summary\n",
      "Hyperparameters:\n",
      "dropout: 0.0\n",
      "learning_rate: 0.01\n",
      "Score: 0.5\n",
      "\n",
      "********************************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#200 state dimensions batch_size 32\n",
    "X200_train = sequence.pad_sequences(X_train, maxlen=200)\n",
    "X200_test = sequence.pad_sequences(X_test, maxlen=200)\n",
    "bsize = 32\n",
    "X_valid, y_valid = X200_train[:bsize], y_train[:bsize]\n",
    "X_train2, y_train2 = X200_train[bsize:], y_train[bsize:]\n",
    "tuner = RandomSearch(\n",
    "    build_model200,\n",
    "    objective=\"accuracy\",\n",
    "    max_trials=3,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"helloworld\",\n",
    ")\n",
    "tuner.search(X_train2, y_train2, epochs=3, validation_data=(X_valid, y_valid), batch_size = bsize)\n",
    "tuner.results_summary()\n",
    "print(\"\\n********************************************************************************\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dead96ef",
   "metadata": {},
   "source": [
    "## batch size 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cec852b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 03m 21s]\n",
      "val_accuracy: 1.0\n",
      "\n",
      "Best val_accuracy So Far: 1.0\n",
      "Total elapsed time: 00h 10m 17s\n",
      "Results summary\n",
      "Results in my_dir\\helloworld\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 0 summary\n",
      "Hyperparameters:\n",
      "dropout: 0.4\n",
      "learning_rate: 0.001\n",
      "Score: 1.0\n",
      "\n",
      "Trial 1 summary\n",
      "Hyperparameters:\n",
      "dropout: 0.4\n",
      "learning_rate: 0.0001\n",
      "Score: 1.0\n",
      "\n",
      "Trial 2 summary\n",
      "Hyperparameters:\n",
      "dropout: 0.0\n",
      "learning_rate: 0.01\n",
      "Score: 1.0\n",
      "\n",
      "********************************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#200 state dimensions batch_size 64\n",
    "X200_train = sequence.pad_sequences(X_train, maxlen=200)\n",
    "X200_test = sequence.pad_sequences(X_test, maxlen=200)\n",
    "bsize = 64\n",
    "X_valid, y_valid = X200_train[:bsize], y_train[:bsize]\n",
    "X_train2, y_train2 = X200_train[bsize:], y_train[bsize:]\n",
    "tuner = RandomSearch(\n",
    "    build_model200,\n",
    "    objective=\"accuracy\",\n",
    "    max_trials=3,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"helloworld\",\n",
    ")\n",
    "tuner.search(X_train2, y_train2, epochs=3, validation_data=(X_valid, y_valid), batch_size = bsize)\n",
    "tuner.results_summary()\n",
    "print(\"\\n********************************************************************************\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32982bd7",
   "metadata": {},
   "source": [
    "## batch size 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101ddd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 02m 58s]\n",
      "val_accuracy: 0.5\n",
      "\n",
      "Best val_accuracy So Far: 1.0\n",
      "Total elapsed time: 00h 10m 11s\n",
      "Results summary\n",
      "Results in my_dir\\helloworld\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 1 summary\n",
      "Hyperparameters:\n",
      "dropout: 0.5\n",
      "learning_rate: 0.01\n",
      "Score: 1.0\n",
      "\n",
      "Trial 0 summary\n",
      "Hyperparameters:\n",
      "dropout: 0.0\n",
      "learning_rate: 0.01\n",
      "Score: 0.5\n",
      "\n",
      "Trial 2 summary\n",
      "Hyperparameters:\n",
      "dropout: 0.0\n",
      "learning_rate: 0.001\n",
      "Score: 0.5\n",
      "\n",
      "********************************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#200 state dimensions batch_size 96\n",
    "X200_train = sequence.pad_sequences(X_train, maxlen=200)\n",
    "X200_test = sequence.pad_sequences(X_test, maxlen=200)\n",
    "bsize = 96\n",
    "X_valid, y_valid = X200_train[:bsize], y_train[:bsize]\n",
    "X_train2, y_train2 = X200_train[bsize:], y_train[bsize:]\n",
    "tuner = RandomSearch(\n",
    "    build_model200,\n",
    "    objective=\"accuracy\",\n",
    "    max_trials=3,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"helloworld\",\n",
    ")\n",
    "tuner.search(X_train2, y_train2, epochs=3, validation_data=(X_valid, y_valid), batch_size = bsize)\n",
    "tuner.results_summary()\n",
    "print(\"\\n********************************************************************************\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b300849",
   "metadata": {},
   "source": [
    "# State dimensions 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974a65d7",
   "metadata": {},
   "source": [
    "## batch size 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29e4ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 10m 22s]\n",
      "val_accuracy: 1.0\n",
      "\n",
      "Best val_accuracy So Far: 1.0\n",
      "Total elapsed time: 00h 18m 17s\n",
      "\n",
      "Search: Running Trial #3\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "0.5               |0                 |dropout\n",
      "0.001             |0.0001            |learning_rate\n",
      "\n",
      "Epoch 1/3\n",
      "161/781 [=====>........................] - ETA: 1:34 - loss: 0.6988 - accuracy: 0.5076"
     ]
    }
   ],
   "source": [
    "#500 state dimensions batch_size 32\n",
    "X500_train = sequence.pad_sequences(X_train, maxlen=500)\n",
    "X500_test = sequence.pad_sequences(X_test, maxlen=500)\n",
    "bsize = 32\n",
    "X_valid, y_valid = X500_train[:bsize], y_train[:bsize]\n",
    "X_train2, y_train2 = X500_train[bsize:], y_train[bsize:]\n",
    "tuner = RandomSearch(\n",
    "    build_model500,\n",
    "    objective=\"accuracy\",\n",
    "    max_trials=3,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"helloworld\",\n",
    ")\n",
    "tuner.search(X_train2, y_train2, epochs=3, validation_data=(X_valid, y_valid), batch_size = bsize)\n",
    "tuner.results_summary()\n",
    "print(\"\\n********************************************************************************\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcf8959",
   "metadata": {},
   "source": [
    "## batch size 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7fe26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#500 state dimensions batch_size 64\n",
    "X500_train = sequence.pad_sequences(X_train, maxlen=500)\n",
    "X500_test = sequence.pad_sequences(X_test, maxlen=500)\n",
    "bsize = 64\n",
    "X_valid, y_valid = X500_train[:bsize], y_train[:bsize]\n",
    "X_train2, y_train2 = X500_train[bsize:], y_train[bsize:]\n",
    "tuner = RandomSearch(\n",
    "    build_model500,\n",
    "    objective=\"accuracy\",\n",
    "    max_trials=3,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"helloworld\",\n",
    ")\n",
    "tuner.search(X_train2, y_train2, epochs=3, validation_data=(X_valid, y_valid), batch_size = bsize)\n",
    "tuner.results_summary()\n",
    "print(\"\\n********************************************************************************\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816fc947",
   "metadata": {},
   "source": [
    "## batch size 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06abf86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#500 state dimensions batch_size 96\n",
    "X500_train = sequence.pad_sequences(X_train, maxlen=500)\n",
    "X500_test = sequence.pad_sequences(X_test, maxlen=500)\n",
    "bsize = 96\n",
    "X_valid, y_valid = X500_train[:bsize], y_train[:bsize]\n",
    "X_train2, y_train2 = X500_train[bsize:], y_train[bsize:]\n",
    "tuner = RandomSearch(\n",
    "    build_model500,\n",
    "    objective=\"accuracy\",\n",
    "    max_trials=3,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"helloworld\",\n",
    ")\n",
    "tuner.search(X_train2, y_train2, epochs=3, validation_data=(X_valid, y_valid), batch_size = bsize)\n",
    "tuner.results_summary()\n",
    "print(\"\\n********************************************************************************\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9a989c",
   "metadata": {},
   "source": [
    "# Selecting the best models and getting the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59805cd",
   "metadata": {},
   "source": [
    "## Dimension 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9d5515",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=[]\n",
    "\n",
    "X20_train = sequence.pad_sequences(X_train, maxlen=20)\n",
    "X20_test = sequence.pad_sequences(X_test, maxlen=20)\n",
    "bsize = 64\n",
    "X_valid, y_valid = X20_train[:bsize], y_train[:bsize]\n",
    "X_train2, y_train2 = X20_train[bsize:], y_train[bsize:]\n",
    "\n",
    "vocab_size = 5000\n",
    "embedding_size = 128\n",
    "num_epochs = 3\n",
    "model=Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_size, input_length=20))\n",
    "model.add(SimpleRNN(units=128, input_shape=(None, 1), dropout = 0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#print(model.summary())\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "             optimizer=keras.optimizers.Adam(lr=0.001), \n",
    "             metrics=['accuracy'])\n",
    "model.fit(X_train2, y_train2, validation_data=(X_valid, y_valid), batch_size=bsize, epochs=num_epochs)\n",
    "score = model.evaluate(X20_test, y_test, verbose=0)\n",
    "print('Testing Accuracy:', score[1])\n",
    "acc.append(score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4dfa59",
   "metadata": {},
   "source": [
    "## Dimension 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e9d939",
   "metadata": {},
   "outputs": [],
   "source": [
    "X50_train = sequence.pad_sequences(X_train, maxlen=50)\n",
    "X50_test = sequence.pad_sequences(X_test, maxlen=50)\n",
    "bsize = 96\n",
    "X_valid, y_valid = X50_train[:bsize], y_train[:bsize]\n",
    "X_train2, y_train2 = X50_train[bsize:], y_train[bsize:]\n",
    "\n",
    "vocab_size = 5000\n",
    "embedding_size = 128\n",
    "num_epochs = 3\n",
    "model=Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_size, input_length=50))\n",
    "model.add(SimpleRNN(units=128, input_shape=(None, 1), dropout = 0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#print(model.summary())\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "             optimizer=keras.optimizers.Adam(lr=0.001), \n",
    "             metrics=['accuracy'])\n",
    "model.fit(X_train2, y_train2, validation_data=(X_valid, y_valid), batch_size=bsize, epochs=num_epochs)\n",
    "score = model.evaluate(X50_test, y_test, verbose=0)\n",
    "print('Testing Accuracy:', score[1])\n",
    "acc.append(score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f214c35",
   "metadata": {},
   "source": [
    "## Dimension 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69abeb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "X100_train = sequence.pad_sequences(X_train, maxlen=100)\n",
    "X100_test = sequence.pad_sequences(X_test, maxlen=100)\n",
    "bsize = 32\n",
    "X_valid, y_valid = X100_train[:bsize], y_train[:bsize]\n",
    "X_train2, y_train2 = X100_train[bsize:], y_train[bsize:]\n",
    "\n",
    "vocab_size = 5000\n",
    "embedding_size = 128\n",
    "num_epochs = 3\n",
    "model=Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_size, input_length=100))\n",
    "model.add(SimpleRNN(units=128, input_shape=(None, 1), dropout = 0.6))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#print(model.summary())\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "             optimizer=keras.optimizers.Adam(lr=0.0001), \n",
    "             metrics=['accuracy'])\n",
    "model.fit(X_train2, y_train2, validation_data=(X_valid, y_valid), batch_size=bsize, epochs=num_epochs)\n",
    "score = model.evaluate(X100_test, y_test, verbose=0)\n",
    "print('Testing Accuracy:', score[1])\n",
    "acc.append(score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c36d31d",
   "metadata": {},
   "source": [
    "## Dimension 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9281bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X200_train = sequence.pad_sequences(X_train, maxlen=200)\n",
    "X200_test = sequence.pad_sequences(X_test, maxlen=200)\n",
    "bsize = 32\n",
    "X_valid, y_valid = X200_train[:bsize], y_train[:bsize]\n",
    "X_train2, y_train2 = X200_train[bsize:], y_train[bsize:]\n",
    "\n",
    "vocab_size = 5000\n",
    "embedding_size = 128\n",
    "num_epochs = 3\n",
    "model=Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_size, input_length=200))\n",
    "model.add(SimpleRNN(units=128, input_shape=(None, 1), dropout = 0.6))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#print(model.summary())\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "             optimizer=keras.optimizers.Adam(lr=0.0001), \n",
    "             metrics=['accuracy'])\n",
    "model.fit(X_train2, y_train2, validation_data=(X_valid, y_valid), batch_size=bsize, epochs=num_epochs)\n",
    "score = model.evaluate(X200_test, y_test, verbose=0)\n",
    "print('Testing Accuracy:', score[1])\n",
    "acc.append(score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5061ddf",
   "metadata": {},
   "source": [
    "## Dimension 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99363d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X500_train = sequence.pad_sequences(X_train, maxlen=500)\n",
    "X500_test = sequence.pad_sequences(X_test, maxlen=500)\n",
    "bsize = 32\n",
    "X_valid, y_valid = X500_train[:bsize], y_train[:bsize]\n",
    "X_train2, y_train2 = X500_train[bsize:], y_train[bsize:]\n",
    "\n",
    "vocab_size = 5000\n",
    "embedding_size = 128\n",
    "num_epochs = 3\n",
    "model=Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_size, input_length=500))\n",
    "model.add(SimpleRNN(units=128, input_shape=(None, 1), dropout = 0.0))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#print(model.summary())\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "             optimizer=keras.optimizers.Adam(lr=0.0001), \n",
    "             metrics=['accuracy'])\n",
    "model.fit(X_train2, y_train2, validation_data=(X_valid, y_valid), batch_size=bsize, epochs=num_epochs)\n",
    "score = model.evaluate(X500_test, y_test, verbose=0)\n",
    "print('Testing Accuracy:', score[1])\n",
    "acc.append(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ffa53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "simplernnacc = \"\"\n",
    "for i in acc:\n",
    "    simplernnacc += str(i) + \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c5361e",
   "metadata": {},
   "outputs": [],
   "source": [
    "simplernnacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3ed678",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"simplernnacc.txt\", \"w\") as f:\n",
    "    f.write(simplernnacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5e74d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = [20,50,100,200,500]\n",
    "plt.plot(dimensions, acc)\n",
    "plt.ylabel('Vanilla Rnn Accuracies')\n",
    "plt.xlabel('State dimensions')\n",
    "plt.title('Vainlla RNN with IMDB database test data accuracies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befb1758",
   "metadata": {},
   "source": [
    "\n",
    "# LSTM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd3dba5",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0800e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_modellstm20(hp):\n",
    "    vocab_size = 5000\n",
    "    embedding_size = 128\n",
    "    model=Sequential()\n",
    "    model.add(Embedding(vocab_size, embedding_size, input_length=20))\n",
    "    model.add(LSTM(units=128, input_shape=(None, 1), dropout = hp.Choice(\"dropout\", values=[0.0, 0.4, 0.5, 0.6])))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    #print(model.summary())\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                 optimizer=keras.optimizers.Adam(hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4])), \n",
    "                 metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_modellstm50(hp):\n",
    "    vocab_size = 5000\n",
    "    embedding_size = 128\n",
    "    model=Sequential()\n",
    "    model.add(Embedding(vocab_size, embedding_size, input_length=50))\n",
    "    model.add(LSTM(units=128, input_shape=(None, 1), dropout = hp.Choice(\"dropout\", values=[0.0, 0.4, 0.5, 0.6])))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    #print(model.summary())\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                 optimizer=keras.optimizers.Adam(hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4])), \n",
    "                 metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_modellstm100(hp):\n",
    "    vocab_size = 5000\n",
    "    embedding_size = 128\n",
    "    model=Sequential()\n",
    "    model.add(Embedding(vocab_size, embedding_size, input_length=100))\n",
    "    model.add(LSTM(units=128, input_shape=(None, 1), dropout = hp.Choice(\"dropout\", values=[0.0, 0.4, 0.5, 0.6])))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    #print(model.summary())\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                 optimizer=keras.optimizers.Adam(hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4])), \n",
    "                 metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_modellstm200(hp):\n",
    "    vocab_size = 5000\n",
    "    embedding_size = 128\n",
    "    model=Sequential()\n",
    "    model.add(Embedding(vocab_size, embedding_size, input_length=200))\n",
    "    model.add(LSTM(units=128, input_shape=(None, 1), dropout = hp.Choice(\"dropout\", values=[0.0, 0.4, 0.5, 0.6])))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    #print(model.summary())\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                 optimizer=keras.optimizers.Adam(hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4])), \n",
    "                 metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_modellstm500(hp):\n",
    "    vocab_size = 5000\n",
    "    embedding_size = 128\n",
    "    model=Sequential()\n",
    "    model.add(Embedding(vocab_size, embedding_size, input_length=500))\n",
    "    model.add(LSTM(units=128, input_shape=(None, 1), dropout = hp.Choice(\"dropout\", values=[0.0, 0.4, 0.5, 0.6])))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    #print(model.summary())\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                 optimizer=keras.optimizers.Adam(hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4])), \n",
    "                 metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67802252",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning for state dimensions = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12967d21",
   "metadata": {},
   "source": [
    "## batchsize 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03bfc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#20 state dimensions batch_size 32\n",
    "X20_train = sequence.pad_sequences(X_train, maxlen=20)\n",
    "X20_test = sequence.pad_sequences(X_test, maxlen=20)\n",
    "bsize = 32\n",
    "X_valid, y_valid = X20_train[:bsize], y_train[:bsize]\n",
    "X_train2, y_train2 = X20_train[bsize:], y_train[bsize:]\n",
    "tuner = RandomSearch(\n",
    "    build_modellstm20,\n",
    "    objective=\"accuracy\",\n",
    "    max_trials=3,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"helloworld\",\n",
    ")\n",
    "tuner.search(X_train2, y_train2, epochs=3, validation_data=(X_valid, y_valid), batch_size = bsize)\n",
    "tuner.results_summary()\n",
    "print(\"\\n********************************************************************************\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13403269",
   "metadata": {},
   "source": [
    "## batchsize 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf0bae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#20 state dimensions batch_size 64\n",
    "X20_train = sequence.pad_sequences(X_train, maxlen=20)\n",
    "X20_test = sequence.pad_sequences(X_test, maxlen=20)\n",
    "bsize = 64\n",
    "X_valid, y_valid = X20_train[:bsize], y_train[:bsize]\n",
    "X_train2, y_train2 = X20_train[bsize:], y_train[bsize:]\n",
    "tuner = RandomSearch(\n",
    "    build_modellstm20,\n",
    "    objective=\"accuracy\",\n",
    "    max_trials=3,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"helloworld\",\n",
    ")\n",
    "tuner.search(X_train2, y_train2, epochs=3, validation_data=(X_valid, y_valid), batch_size = bsize)\n",
    "tuner.results_summary()\n",
    "print(\"\\n********************************************************************************\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1f4535",
   "metadata": {},
   "source": [
    "## batch size 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acfb0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#20 state dimensions batch_size 96\n",
    "X20_train = sequence.pad_sequences(X_train, maxlen=20)\n",
    "X20_test = sequence.pad_sequences(X_test, maxlen=20)\n",
    "bsize = 96\n",
    "X_valid, y_valid = X20_train[:bsize], y_train[:bsize]\n",
    "X_train2, y_train2 = X20_train[bsize:], y_train[bsize:]\n",
    "tuner = RandomSearch(\n",
    "    build_modellstm20,\n",
    "    objective=\"accuracy\",\n",
    "    max_trials=3,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"helloworld\",\n",
    ")\n",
    "tuner.search(X_train2, y_train2, epochs=3, validation_data=(X_valid, y_valid), batch_size = bsize)\n",
    "tuner.results_summary()\n",
    "print(\"\\n********************************************************************************\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8169701",
   "metadata": {},
   "source": [
    "# State dimensions 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db1adf0",
   "metadata": {},
   "source": [
    "## batch size 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e826c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#50 state dimensions batch_size 32\n",
    "X50_train = sequence.pad_sequences(X_train, maxlen=50)\n",
    "X50_test = sequence.pad_sequences(X_test, maxlen=50)\n",
    "bsize = 32\n",
    "X_valid, y_valid = X50_train[:bsize], y_train[:bsize]\n",
    "X_train2, y_train2 = X50_train[bsize:], y_train[bsize:]\n",
    "tuner = RandomSearch(\n",
    "    build_modellstm50,\n",
    "    objective=\"accuracy\",\n",
    "    max_trials=3,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"helloworld\",\n",
    ")\n",
    "tuner.search(X_train2, y_train2, epochs=3, validation_data=(X_valid, y_valid), batch_size = bsize)\n",
    "tuner.results_summary()\n",
    "print(\"\\n********************************************************************************\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881b87d2",
   "metadata": {},
   "source": [
    "## batch size 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a037ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#50 state dimensions batch_size 64\n",
    "X50_train = sequence.pad_sequences(X_train, maxlen=50)\n",
    "X50_test = sequence.pad_sequences(X_test, maxlen=50)\n",
    "bsize = 64\n",
    "X_valid, y_valid = X50_train[:bsize], y_train[:bsize]\n",
    "X_train2, y_train2 = X50_train[bsize:], y_train[bsize:]\n",
    "tuner = RandomSearch(\n",
    "    build_modellstm50,\n",
    "    objective=\"accuracy\",\n",
    "    max_trials=3,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"helloworld\",\n",
    ")\n",
    "tuner.search(X_train2, y_train2, epochs=3, validation_data=(X_valid, y_valid), batch_size = bsize)\n",
    "tuner.results_summary()\n",
    "print(\"\\n********************************************************************************\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2849a754",
   "metadata": {},
   "source": [
    "## batch size 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1615cfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#50 state dimensions batch_size 96\n",
    "X50_train = sequence.pad_sequences(X_train, maxlen=50)\n",
    "X50_test = sequence.pad_sequences(X_test, maxlen=50)\n",
    "bsize = 96\n",
    "X_valid, y_valid = X50_train[:bsize], y_train[:bsize]\n",
    "X_train2, y_train2 = X50_train[bsize:], y_train[bsize:]\n",
    "tuner = RandomSearch(\n",
    "    build_modellstm50,\n",
    "    objective=\"accuracy\",\n",
    "    max_trials=3,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"helloworld\",\n",
    ")\n",
    "tuner.search(X_train2, y_train2, epochs=3, validation_data=(X_valid, y_valid), batch_size = bsize)\n",
    "tuner.results_summary()\n",
    "print(\"\\n********************************************************************************\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d46b428",
   "metadata": {},
   "source": [
    "# State dimensions 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744ad911",
   "metadata": {},
   "source": [
    "## batch size 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10aa59c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#100 state dimensions batch_size 32\n",
    "X100_train = sequence.pad_sequences(X_train, maxlen=100)\n",
    "X100_test = sequence.pad_sequences(X_test, maxlen=100)\n",
    "bsize = 32\n",
    "X_valid, y_valid = X100_train[:bsize], y_train[:bsize]\n",
    "X_train2, y_train2 = X100_train[bsize:], y_train[bsize:]\n",
    "tuner = RandomSearch(\n",
    "    build_modellstm100,\n",
    "    objective=\"accuracy\",\n",
    "    max_trials=3,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"helloworld\",\n",
    ")\n",
    "tuner.search(X_train2, y_train2, epochs=3, validation_data=(X_valid, y_valid), batch_size = bsize)\n",
    "tuner.results_summary()\n",
    "print(\"\\n********************************************************************************\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3e52e3",
   "metadata": {},
   "source": [
    "## batch size 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e401a6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#100 state dimensions batch_size 64\n",
    "X100_train = sequence.pad_sequences(X_train, maxlen=100)\n",
    "X100_test = sequence.pad_sequences(X_test, maxlen=100)\n",
    "bsize = 64\n",
    "X_valid, y_valid = X100_train[:bsize], y_train[:bsize]\n",
    "X_train2, y_train2 = X100_train[bsize:], y_train[bsize:]\n",
    "tuner = RandomSearch(\n",
    "    build_modellstm100,\n",
    "    objective=\"accuracy\",\n",
    "    max_trials=3,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"helloworld\",\n",
    ")\n",
    "tuner.search(X_train2, y_train2, epochs=3, validation_data=(X_valid, y_valid), batch_size = bsize)\n",
    "tuner.results_summary()\n",
    "print(\"\\n********************************************************************************\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf50469d",
   "metadata": {},
   "source": [
    "## batch size 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954e68f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#100 state dimensions batch_size 96\n",
    "X100_train = sequence.pad_sequences(X_train, maxlen=100)\n",
    "X100_test = sequence.pad_sequences(X_test, maxlen=100)\n",
    "bsize = 96\n",
    "X_valid, y_valid = X100_train[:bsize], y_train[:bsize]\n",
    "X_train2, y_train2 = X100_train[bsize:], y_train[bsize:]\n",
    "tuner = RandomSearch(\n",
    "    build_modellstm100,\n",
    "    objective=\"accuracy\",\n",
    "    max_trials=3,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"helloworld\",\n",
    ")\n",
    "tuner.search(X_train2, y_train2, epochs=3, validation_data=(X_valid, y_valid), batch_size = bsize)\n",
    "tuner.results_summary()\n",
    "print(\"\\n********************************************************************************\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b14bd66",
   "metadata": {},
   "source": [
    "# State dimensions 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871c3a5e",
   "metadata": {},
   "source": [
    "## batch size 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fa90a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#200 state dimensions batch_size 32\n",
    "X200_train = sequence.pad_sequences(X_train, maxlen=200)\n",
    "X200_test = sequence.pad_sequences(X_test, maxlen=200)\n",
    "bsize = 32\n",
    "X_valid, y_valid = X200_train[:bsize], y_train[:bsize]\n",
    "X_train2, y_train2 = X200_train[bsize:], y_train[bsize:]\n",
    "tuner = RandomSearch(\n",
    "    build_modellstm200,\n",
    "    objective=\"accuracy\",\n",
    "    max_trials=3,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"helloworld\",\n",
    ")\n",
    "tuner.search(X_train2, y_train2, epochs=3, validation_data=(X_valid, y_valid), batch_size = bsize)\n",
    "tuner.results_summary()\n",
    "print(\"\\n********************************************************************************\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5600f7e",
   "metadata": {},
   "source": [
    "## batch size 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049ea519",
   "metadata": {},
   "outputs": [],
   "source": [
    "#200 state dimensions batch_size 64\n",
    "X200_train = sequence.pad_sequences(X_train, maxlen=200)\n",
    "X200_test = sequence.pad_sequences(X_test, maxlen=200)\n",
    "bsize = 64\n",
    "X_valid, y_valid = X200_train[:bsize], y_train[:bsize]\n",
    "X_train2, y_train2 = X200_train[bsize:], y_train[bsize:]\n",
    "tuner = RandomSearch(\n",
    "    build_modellstm200,\n",
    "    objective=\"accuracy\",\n",
    "    max_trials=3,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"helloworld\",\n",
    ")\n",
    "tuner.search(X_train2, y_train2, epochs=3, validation_data=(X_valid, y_valid), batch_size = bsize)\n",
    "tuner.results_summary()\n",
    "print(\"\\n********************************************************************************\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652d19e9",
   "metadata": {},
   "source": [
    "## batch size 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1701d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#200 state dimensions batch_size 96\n",
    "X200_train = sequence.pad_sequences(X_train, maxlen=200)\n",
    "X200_test = sequence.pad_sequences(X_test, maxlen=200)\n",
    "bsize = 96\n",
    "X_valid, y_valid = X200_train[:bsize], y_train[:bsize]\n",
    "X_train2, y_train2 = X200_train[bsize:], y_train[bsize:]\n",
    "tuner = RandomSearch(\n",
    "    build_modellstm200,\n",
    "    objective=\"accuracy\",\n",
    "    max_trials=3,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"helloworld\",\n",
    ")\n",
    "tuner.search(X_train2, y_train2, epochs=3, validation_data=(X_valid, y_valid), batch_size = bsize)\n",
    "tuner.results_summary()\n",
    "print(\"\\n********************************************************************************\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33226017",
   "metadata": {},
   "source": [
    "# State dimensions 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833eddfd",
   "metadata": {},
   "source": [
    "## batch size 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43d258e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#500 state dimensions batch_size 32\n",
    "X500_train = sequence.pad_sequences(X_train, maxlen=500)\n",
    "X500_test = sequence.pad_sequences(X_test, maxlen=500)\n",
    "bsize = 32\n",
    "X_valid, y_valid = X500_train[:bsize], y_train[:bsize]\n",
    "X_train2, y_train2 = X500_train[bsize:], y_train[bsize:]\n",
    "tuner = RandomSearch(\n",
    "    build_modellstm500,\n",
    "    objective=\"accuracy\",\n",
    "    max_trials=3,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"helloworld\",\n",
    ")\n",
    "tuner.search(X_train2, y_train2, epochs=3, validation_data=(X_valid, y_valid), batch_size = bsize)\n",
    "tuner.results_summary()\n",
    "print(\"\\n********************************************************************************\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623ea9ed",
   "metadata": {},
   "source": [
    "## batch size 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a56e97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#500 state dimensions batch_size 64\n",
    "X500_train = sequence.pad_sequences(X_train, maxlen=500)\n",
    "X500_test = sequence.pad_sequences(X_test, maxlen=500)\n",
    "bsize = 64\n",
    "X_valid, y_valid = X500_train[:bsize], y_train[:bsize]\n",
    "X_train2, y_train2 = X500_train[bsize:], y_train[bsize:]\n",
    "tuner = RandomSearch(\n",
    "    build_modellstm500,\n",
    "    objective=\"accuracy\",\n",
    "    max_trials=3,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"helloworld\",\n",
    ")\n",
    "tuner.search(X_train2, y_train2, epochs=3, validation_data=(X_valid, y_valid), batch_size = bsize)\n",
    "tuner.results_summary()\n",
    "print(\"\\n********************************************************************************\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec4b7ef",
   "metadata": {},
   "source": [
    "## batch size 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50214c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#500 state dimensions batch_size 96\n",
    "X500_train = sequence.pad_sequences(X_train, maxlen=500)\n",
    "X500_test = sequence.pad_sequences(X_test, maxlen=500)\n",
    "bsize = 96\n",
    "X_valid, y_valid = X500_train[:bsize], y_train[:bsize]\n",
    "X_train2, y_train2 = X500_train[bsize:], y_train[bsize:]\n",
    "tuner = RandomSearch(\n",
    "    build_modellstm500,\n",
    "    objective=\"accuracy\",\n",
    "    max_trials=3,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"helloworld\",\n",
    ")\n",
    "tuner.search(X_train2, y_train2, epochs=3, validation_data=(X_valid, y_valid), batch_size = bsize)\n",
    "tuner.results_summary()\n",
    "print(\"\\n********************************************************************************\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2499057c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d3f9c81",
   "metadata": {},
   "source": [
    "# Selecting the best models and getting the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b05eee",
   "metadata": {},
   "source": [
    "## Dimension 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cf7572",
   "metadata": {},
   "outputs": [],
   "source": [
    "acclstm=[]\n",
    "\n",
    "X20_train = sequence.pad_sequences(X_train, maxlen=20)\n",
    "X20_test = sequence.pad_sequences(X_test, maxlen=20)\n",
    "bsize = 96\n",
    "X_valid, y_valid = X20_train[:bsize], y_train[:bsize]\n",
    "X_train2, y_train2 = X20_train[bsize:], y_train[bsize:]\n",
    "\n",
    "vocab_size = 5000\n",
    "embedding_size = 128\n",
    "num_epochs = 3\n",
    "model=Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_size, input_length=20))\n",
    "model.add(LSTM(units=128, input_shape=(None, 1), dropout = 0.4))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#print(model.summary())\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "             optimizer=keras.optimizers.Adam(lr=0.001), \n",
    "             metrics=['accuracy'])\n",
    "model.fit(X_train2, y_train2, validation_data=(X_valid, y_valid), batch_size=bsize, epochs=num_epochs)\n",
    "score = model.evaluate(X20_test, y_test, verbose=0)\n",
    "print('Testing Accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be270721",
   "metadata": {},
   "outputs": [],
   "source": [
    "acclstm.append(score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49aaa133",
   "metadata": {},
   "source": [
    "## Dimension 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec605c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X50_train = sequence.pad_sequences(X_train, maxlen=50)\n",
    "X50_test = sequence.pad_sequences(X_test, maxlen=50)\n",
    "bsize = 64\n",
    "X_valid, y_valid = X50_train[:bsize], y_train[:bsize]\n",
    "X_train2, y_train2 = X50_train[bsize:], y_train[bsize:]\n",
    "\n",
    "vocab_size = 5000\n",
    "embedding_size = 128\n",
    "num_epochs = 3\n",
    "model=Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_size, input_length=50))\n",
    "model.add(LSTM(units=128, input_shape=(None, 1), dropout = 0.4))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#print(model.summary())\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "             optimizer=keras.optimizers.Adam(lr=0.01), \n",
    "             metrics=['accuracy'])\n",
    "model.fit(X_train2, y_train2, validation_data=(X_valid, y_valid), batch_size=bsize, epochs=num_epochs)\n",
    "score = model.evaluate(X50_test, y_test, verbose=0)\n",
    "print('Testing Accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fb72f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "acclstm[1] = (score[1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ed7a89",
   "metadata": {},
   "source": [
    "## Dimension 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ded69d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X100_train = sequence.pad_sequences(X_train, maxlen=100)\n",
    "X100_test = sequence.pad_sequences(X_test, maxlen=100)\n",
    "bsize = 32\n",
    "X_valid, y_valid = X100_train[:bsize], y_train[:bsize]\n",
    "X_train2, y_train2 = X100_train[bsize:], y_train[bsize:]\n",
    "\n",
    "vocab_size = 5000\n",
    "embedding_size = 128\n",
    "num_epochs = 3\n",
    "model=Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_size, input_length=100))\n",
    "model.add(LSTM(units=128, input_shape=(None, 1), dropout = 0.6))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#print(model.summary())\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "             optimizer=keras.optimizers.Adam(lr=0.0001), \n",
    "             metrics=['accuracy'])\n",
    "model.fit(X_train2, y_train2, validation_data=(X_valid, y_valid), batch_size=bsize, epochs=num_epochs)\n",
    "score = model.evaluate(X100_test, y_test, verbose=0)\n",
    "print('Testing Accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e92a679",
   "metadata": {},
   "outputs": [],
   "source": [
    "acclstm.append(score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14a3c91",
   "metadata": {},
   "source": [
    "## Dimension 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90023f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X200_train = sequence.pad_sequences(X_train, maxlen=200)\n",
    "X200_test = sequence.pad_sequences(X_test, maxlen=200)\n",
    "bsize = 32\n",
    "X_valid, y_valid = X200_train[:bsize], y_train[:bsize]\n",
    "X_train2, y_train2 = X200_train[bsize:], y_train[bsize:]\n",
    "\n",
    "vocab_size = 5000\n",
    "embedding_size = 128\n",
    "num_epochs = 3\n",
    "model=Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_size, input_length=200))\n",
    "model.add(LSTM(units=128, input_shape=(None, 1), dropout = 0.4))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#print(model.summary())\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "             optimizer=keras.optimizers.Adam(lr=0.01), \n",
    "             metrics=['accuracy'])\n",
    "model.fit(X_train2, y_train2, validation_data=(X_valid, y_valid), batch_size=bsize, epochs=num_epochs)\n",
    "score = model.evaluate(X200_test, y_test, verbose=0)\n",
    "print('Testing Accuracy:', score[1])\n",
    "acclstm.append(score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64012c59",
   "metadata": {},
   "source": [
    "## Dimension 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844ed6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X500_train = sequence.pad_sequences(X_train, maxlen=500)\n",
    "X500_test = sequence.pad_sequences(X_test, maxlen=500)\n",
    "bsize = 32\n",
    "X_valid, y_valid = X500_train[:bsize], y_train[:bsize]\n",
    "X_train2, y_train2 = X500_train[bsize:], y_train[bsize:]\n",
    "\n",
    "vocab_size = 5000\n",
    "embedding_size = 128\n",
    "num_epochs = 3\n",
    "model=Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_size, input_length=500))\n",
    "model.add(LSTM(units=128, input_shape=(None, 1), dropout = 0.4))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#print(model.summary())\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "             optimizer=keras.optimizers.Adam(lr=0.0001), \n",
    "             metrics=['accuracy'])\n",
    "model.fit(X_train2, y_train2, validation_data=(X_valid, y_valid), batch_size=bsize, epochs=num_epochs)\n",
    "score = model.evaluate(X500_test, y_test, verbose=0)\n",
    "print('Testing Accuracy:', score[1])\n",
    "acclstm.append(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b686d23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstmacc = \"\"\n",
    "for i in acclstm:\n",
    "    lstmacc += str(i) + \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703ccd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstmacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8467e071",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"lstmacc.txt\", \"w\") as f:\n",
    "    f.write(lstmacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd31eaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = [20,50,100,200,500]\n",
    "plt.plot(dimensions, acclstm)\n",
    "plt.ylabel('LSTM Accuracies')\n",
    "plt.xlabel('State dimensions')\n",
    "plt.title('LSTM with IMDB database test data accuracies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdb0c1d",
   "metadata": {},
   "source": [
    "# Combining the Results of LSTM and Vanilla RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e63012",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plt.plot(dimensions,acc,color='b',linestyle='solid',label='Vanilla RNN')\n",
    "plt.plot(dimensions,acclstm,color='g',linestyle='solid',label='LSTM')\n",
    "\n",
    "plt.title('Model-wise accuracy comparison')\n",
    "plt.xlabel('State Dimensions')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bcc81f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
